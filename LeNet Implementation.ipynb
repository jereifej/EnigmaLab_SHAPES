{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.models import Sequential\n",
    "import keras.layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# image functions\n",
    "def convert(img, target_type_min, target_type_max, target_type):\n",
    "    imin = img.min()\n",
    "    imax = img.max()\n",
    "\n",
    "    a = (target_type_max - target_type_min) / (imax - imin)\n",
    "    b = target_type_max - a * imax\n",
    "    new_img = (a * img + b).astype(target_type)\n",
    "    return new_img\n",
    "def toGray(im, im_L=10, im_W=10, contrast=1.0):\n",
    "    # normalize\n",
    "    gray = np.zeros([im_L, im_W])\n",
    "    for j in range(im_L):\n",
    "        for i in range(im_W):\n",
    "            gray[j][i] = max(im[j][i]) * contrast\n",
    "    gray = convert(gray, 0, 255, np.uint8)\n",
    "    return gray"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ereij\\AppData\\Local\\Temp\\ipykernel_9968\\2359215898.py:6: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  a = (target_type_max - target_type_min) / (imax - imin)\n",
      "C:\\Users\\ereij\\AppData\\Local\\Temp\\ipykernel_9968\\2359215898.py:8: RuntimeWarning: invalid value encountered in add\n",
      "  new_img = (a * img + b).astype(target_type)\n",
      "C:\\Users\\ereij\\AppData\\Local\\Temp\\ipykernel_9968\\2359215898.py:8: RuntimeWarning: invalid value encountered in cast\n",
      "  new_img = (a * img + b).astype(target_type)\n"
     ]
    }
   ],
   "source": [
    "# import data and label data\n",
    "num_samples = 180\n",
    "sample_set = np.empty([num_samples*9, 10, 10])\n",
    "sample_labels = np.empty(num_samples*9)\n",
    "baseDir = 'ShapeGroups'\n",
    "idx = 0\n",
    "shape_id = 0\n",
    "for filename in os.listdir(baseDir):\n",
    "    folder = baseDir + '/' + filename\n",
    "    for imagepath in os.listdir(folder):\n",
    "        imagepathFull = folder + '/' + imagepath\n",
    "        sample_set[idx] = toGray(cv2.imread(imagepathFull))\n",
    "        sample_labels[idx] = shape_id\n",
    "        # print(\"\\n\" + im\n",
    "        # print(training_set[idx])\n",
    "        idx += 1\n",
    "    shape_id += 1\n",
    "sample_set = sample_set[0:idx,]\n",
    "sample_labels = sample_labels[0:idx,]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "# add padding - 11 rows and columns on each side for 32x32\n",
    "sample_size = len(sample_set)\n",
    "X_set = np.empty([sample_size, 32, 32])\n",
    "for idx in range(sample_size):\n",
    "    X_set[idx] = np.pad(sample_set[idx], ((11, 11), (11, 11)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "print(np.shape(X_set[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075\n",
      "530\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_set, sample_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "# print(Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d_6 (Avera  (None, 15, 15, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_7 (Avera  (None, 6, 6, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               69240     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 595       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80939 (316.17 KB)\n",
      "Trainable params: 80939 (316.17 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution 1: Input = 32x32x1, Output = 28x28x6\n",
    "# Subsampling 1: Input = 28x28x6, Output = 14x14x6\n",
    "model.add(keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "model.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "# Convolution 2: Input = 14x14x6, Output = 10x10x16\n",
    "# Subsampling 2: Input = 10x10x16, Output = 5x5x16\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Input = 5x5x16, Output = 120\n",
    "model.add(keras.layers.Dense(units=120, activation='relu'))\n",
    "# Input = 120, Output = 84\n",
    "model.add(keras.layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# Softmax output - modified for 7 shapes\n",
    "model.add(keras.layers.Dense(units=7, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 39ms/step - loss: 6.7994 - accuracy: 0.3228 - val_loss: 3.2473 - val_accuracy: 0.5811\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.6346 - accuracy: 0.6856 - val_loss: 1.0850 - val_accuracy: 0.7811\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.7531 - accuracy: 0.8809 - val_loss: 0.5763 - val_accuracy: 0.9113\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.4554 - accuracy: 0.9451 - val_loss: 0.4003 - val_accuracy: 0.9415\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.2685 - accuracy: 0.9619 - val_loss: 0.1857 - val_accuracy: 0.9792\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1221 - accuracy: 0.9749 - val_loss: 0.1054 - val_accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.0766 - accuracy: 0.9740 - val_loss: 0.0846 - val_accuracy: 0.9698\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0696 - accuracy: 0.9721 - val_loss: 0.0745 - val_accuracy: 0.9774\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0616 - accuracy: 0.9758 - val_loss: 0.0693 - val_accuracy: 0.9755\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0592 - accuracy: 0.9740 - val_loss: 0.0637 - val_accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN model iteratively for n_epochs\n",
    "n_epochs = 10\n",
    "history = model.fit(x=X_train,y=Y_train, epochs=n_epochs, batch_size=128, validation_data=(X_test, Y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.92647059 1.         0.90789474\n",
      " 1.        ]\n",
      "[1.         1.         1.         0.92215569 1.         0.93700787\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "def calc_Categorical_Accuracy(test, truth, num_categories):\n",
    "    truth = truth.astype(int)\n",
    "    certainty = model.predict(test, verbose=0)\n",
    "    decision = np.argmax(certainty, axis=1)  # find index of max probability\n",
    "\n",
    "    categorical_accuracy = np.zeros(shape=(num_categories,))\n",
    "    for i in range(len(decision)):\n",
    "      if decision[i] == truth[i]:\n",
    "          categorical_accuracy[truth[i]] = categorical_accuracy[truth[i]]+1\n",
    "\n",
    "    for i in range(num_categories):\n",
    "        num_tests = truth.tolist().count(i)\n",
    "        categorical_accuracy[i] = categorical_accuracy[i]/num_tests\n",
    "    return categorical_accuracy\n",
    "\n",
    "acc = calc_Categorical_Accuracy(X_test, Y_test, 7)\n",
    "print(acc)\n",
    "\n",
    "acc = calc_Categorical_Accuracy(X_train, Y_train, 7)\n",
    "print(acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
